{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import logging\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from utils.utils import compute_topk, collate_fn\n",
    "from data.dataloader import ITM_Dataset\n",
    "import yaml\n",
    "from attrdict import AttrDict\n",
    "from models.model_zoo import ViT_NumScore\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "if __name__ == '__main__':\n",
    "    with open('configs.yaml') as f:\n",
    "        test_args = yaml.load(f, Loader=yaml.FullLoader)['test']\n",
    "        args = AttrDict(test_args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# prepare dataset\n",
    "test_dataset = ITM_Dataset(args.image_root_path,\n",
    "                            args.sentence_file_path,\n",
    "                            'test',\n",
    "                            args.max_length)\n",
    "test_loader = data.DataLoader(test_dataset, \n",
    "                               args.batch_size, \n",
    "                               collate_fn=lambda b: collate_fn(b, args.max_length),\n",
    "                               shuffle=False, \n",
    "                               num_workers=8,\n",
    "                               pin_memory=True,\n",
    "                               drop_last=True)\n",
    "print('Data loaded')\n",
    "\n",
    "ac_i2t_top1_best = 0.0\n",
    "ac_i2t_top10_best = 0.0\n",
    "ac_t2i_top1_best = 0.0\n",
    "ac_t2i_top10_best = 0.0\n",
    "i2t_model = '1.pth.tar'\n",
    "model_file = os.path.join(args.checkpoint_dir, '1.pth.tar')\n",
    "epoch = i2t_model.split('.')[0]\n",
    "network = ViT_NumScore()\n",
    "network = network.cuda()\n",
    "network_dict = network.state_dict()\n",
    "pretrained_dict = torch.load(model_file)['network']\n",
    "# process keyword of pretrained model\n",
    "prefix = 'module.image_model.'\n",
    "pretrained_dict = {prefix + k[:] :v for k,v in pretrained_dict.items()}\n",
    "pretrained_dict = {k:v for k,v in pretrained_dict.items() if k in network_dict}\n",
    "network_dict.update(pretrained_dict)\n",
    "network.load_state_dict(network_dict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data loaded\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at /home/giang/.cache/torch/sentence_transformers/sbert.net_models_bert-base-nli-stsb-mean-tokens/0_BERT were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def topk(sim, labels, k=[1, 10]):\n",
    "    result = []\n",
    "    maxk = max(k)\n",
    "    size_total = len(labels)\n",
    "    _, pred_index = sim.topk(maxk, 0, True, True)\n",
    "    pred_labels = labels[pred_index]\n",
    "    print(pred_labels)\n",
    "    correct = pred_labels.eq(labels.view(1,-1).expand_as(pred_labels))\n",
    "    for topk in k:\n",
    "        correct_k = torch.sum(correct[:topk], dim=0)\n",
    "        correct_k = torch.sum(correct_k > 0).float()\n",
    "        result.append(correct_k * 100 / size_total)\n",
    "    return result\n",
    "# switch to evaluate mode\n",
    "network.eval()\n",
    "images_bank = []\n",
    "text_bank = []\n",
    "labels_bank = []\n",
    "index = 0\n",
    "with torch.no_grad():\n",
    "    for images, input_ids, token_type_ids, attention_masks, labels in test_loader:\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "        input_ids = input_ids.cuda()\n",
    "        token_type_ids = token_type_ids.cuda()\n",
    "        attention_masks = attention_masks.cuda()\n",
    "\n",
    "        interval = images.shape[0]\n",
    "        image_embeddings, text_embeddings = network(images, input_ids, token_type_ids, attention_masks, val=True)\n",
    "        images_bank.append(image_embeddings)\n",
    "        text_bank.append(text_embeddings)\n",
    "        labels_bank.append(labels)\n",
    "\n",
    "        index = index + interval\n",
    "\n",
    "\n",
    "    images_bank = torch.cat(images_bank[:index], dim=0)\n",
    "    text_bank = torch.cat(text_bank[:index], dim=0)\n",
    "    labels_bank = torch.cat(labels_bank[:index], dim=0)\n",
    "\n",
    "    images_bank = images_bank[:100]\n",
    "    text_bank = text_bank[:100]\n",
    "    labels_bank = labels_bank[:100]\n",
    "\n",
    "    scoring_i2t, scoring_t2i = network.scoring_i2t, network.scoring_t2i\n",
    "    images_embeddings = images_bank\n",
    "    text_embeddings = text_bank\n",
    "    labels = labels_bank\n",
    "\n",
    "    images_embeddings_norm = images_embeddings/images_embeddings.norm(dim=2)[:, :, None]\n",
    "    text_embeddings_norm = text_embeddings/text_embeddings.norm(dim=1)[:, None]\n",
    "    batch_size = images_embeddings.shape[0]\n",
    "    i2t = []\n",
    "    t2i = []\n",
    "    for i in tqdm(range(batch_size)):\n",
    "        item_i2t = torch.matmul(images_embeddings[i, :, :].unsqueeze(0), text_embeddings_norm.transpose(0, 1))\n",
    "        item_t2i = torch.matmul(images_embeddings_norm[i, :, :].unsqueeze(0), text_embeddings.transpose(0, 1))\n",
    "\n",
    "        item_i2t, item_t2i = item_i2t.transpose(1, 2), item_t2i.transpose(1, 2)\n",
    "        item_i2t = scoring_i2t(item_i2t).squeeze().unsqueeze(0)\n",
    "        item_t2i = scoring_t2i(item_t2i).squeeze(-1)\n",
    "\n",
    "        i2t.append(item_i2t)\n",
    "        t2i.append(item_t2i)\n",
    "    i2t = torch.cat(i2t, dim=0)\n",
    "    t2i = torch.cat(t2i, dim=0)\n",
    "    t2i = t2i.transpose(0, 1)\n",
    "\n",
    "    result = []\n",
    "    result.extend(topk(i2t, labels, k=[1, 10]))\n",
    "    result.extend(topk(t2i, labels, k=[1, 10]))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 6463.81it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[137, 304,  51, 137, 137,  97,  97, 318,  97,  97, 124, 124, 124, 124,\n",
      "         124, 134,  34,  34, 134, 279, 279, 279, 395,  25, 395, 137, 304, 304,\n",
      "         304, 304, 279, 279, 246, 279, 279, 304, 134, 134, 134, 259,  51,  25,\n",
      "         279, 279, 395, 137, 304,  51, 259,  25, 318, 219,  25, 124, 318, 137,\n",
      "         134, 137, 137, 137, 246,  25, 137,  51,  25,  89, 246, 279, 246, 279,\n",
      "         395, 395,  25, 199, 134,  89,  34, 124,  89,  89,  97, 246,  97,  97,\n",
      "          97,  51, 246, 124, 395, 246,  25,  25,  25, 137,  34, 124, 304, 134,\n",
      "         304, 304],\n",
      "        [137, 304,  51, 137, 137,  97,  97, 318,  97,  97, 124, 124, 124, 124,\n",
      "         124, 134,  34,  34, 134, 279, 279, 279, 395,  25, 395, 137, 304, 304,\n",
      "         304, 304, 279, 279, 246, 279, 279, 304, 134, 134, 134, 259,  51,  25,\n",
      "         279, 279, 395, 137, 304,  51, 259,  25, 318, 219,  25, 124, 318, 137,\n",
      "         134, 137, 137, 137, 246,  25, 137,  51,  25,  89, 246, 279, 246, 279,\n",
      "         395, 395,  25, 199, 134,  89,  34, 124,  89,  89,  97, 246,  97,  97,\n",
      "          97,  51, 246, 124, 395, 246,  25,  25,  25, 137,  34, 124, 304, 134,\n",
      "         304, 304],\n",
      "        [137, 304,  51, 137, 137,  97,  97, 318,  97,  97, 124, 124, 124, 124,\n",
      "         124, 134,  25,  25, 134, 279, 279, 279, 395,  25, 395, 137, 304, 304,\n",
      "         304, 304, 279, 279, 246, 279, 279, 304, 134, 134, 134, 259,  51,  25,\n",
      "         279, 279, 395, 137, 304,  51, 259,  25, 318, 219,  25, 124, 318, 137,\n",
      "         134, 137, 137, 137, 246,  25, 137,  51,  25,  89, 246, 279, 246, 279,\n",
      "         395, 395,  25, 199, 134,  89,  25, 124,  89,  89,  97, 246,  97,  97,\n",
      "          97,  51, 246, 124, 395, 246,  25,  25,  25, 137,  34, 124, 304, 134,\n",
      "         304, 304],\n",
      "        [137, 304,  51, 137, 137,  97,  97, 318,  97,  97, 124, 124, 124, 124,\n",
      "         124, 134,  34,  34, 134, 279, 279, 279, 395,  25, 395, 137, 304, 304,\n",
      "         304, 304, 279, 279, 246, 279, 279, 304, 134, 134, 134, 259,  51,  25,\n",
      "         279, 279, 395, 137, 304,  51, 259,  25, 318, 219,  25, 124, 318, 137,\n",
      "         134, 137, 137, 137, 246,  25, 137,  51,  25,  89, 246, 279, 246, 279,\n",
      "         395, 395,  25, 199, 134,  89,  34, 124,  89,  89,  97, 246,  97,  97,\n",
      "          97,  51, 246, 124, 395, 246,  25,  25,  25, 137,  34, 124, 304, 134,\n",
      "         304, 304],\n",
      "        [137, 304,  51, 137, 137,  97,  97, 318,  97,  97, 124, 124, 124, 124,\n",
      "         124, 134,  25,  25, 134, 279, 279, 279, 395,  25, 395, 137, 304, 304,\n",
      "         304, 304, 279, 279, 246, 279, 279, 304, 134, 134, 134, 259,  51,  25,\n",
      "         279, 279, 395, 137, 304,  51, 259,  25, 318, 219,  25, 124, 318, 137,\n",
      "         134, 137, 137, 137, 246,  25, 137,  51,  25,  89, 246, 279, 246, 279,\n",
      "         395, 395,  25, 199, 134,  89,  25, 124,  89,  89,  97, 246,  97,  97,\n",
      "          97,  51, 246, 124, 395, 246,  25,  25,  25, 137,  34, 124, 304, 134,\n",
      "         304, 304],\n",
      "        [259,  51, 304,  25,  25, 318, 259,  25, 318, 259, 340, 279,  25, 340,\n",
      "         279, 279,  25,  25, 279, 134, 395, 246, 279, 228,  25, 304, 246, 318,\n",
      "         246, 137,  97, 199, 259, 395, 395, 134, 259, 259, 259, 134, 228, 279,\n",
      "          25, 395,  25, 199, 395, 246,  25, 304, 133, 133,  34, 133, 134, 318,\n",
      "         137, 304, 222, 134, 395, 395, 304,  25, 304, 246, 279, 395,  51,  34,\n",
      "          25,  25,  51, 137, 133, 124,  25,  89,  34,  34, 124, 134, 133,  25,\n",
      "         137, 246, 318, 246, 137, 395, 279,  34, 279,  25, 137, 246, 124, 304,\n",
      "         124, 137],\n",
      "        [259,  51, 304,  25,  25, 318, 259,  25, 318, 259, 340, 279,  25, 340,\n",
      "         279, 279,  25,  25, 279, 134, 395, 246, 279, 228,  25, 304, 246, 318,\n",
      "         246, 137,  97, 199, 259, 395, 395, 134, 259, 259, 259, 134, 228, 279,\n",
      "          25, 395,  25, 199, 395, 246,  25, 304, 133, 133,  34, 133, 134, 318,\n",
      "         137, 304, 222, 134, 395, 395, 304,  25, 304, 246, 279, 395,  51,  34,\n",
      "          25,  25,  51, 137, 133, 124,  25,  89,  34,  34, 124, 134, 133,  25,\n",
      "         137, 246, 318, 246, 137, 395, 279,  34, 279,  25, 137, 246, 124, 304,\n",
      "         124, 137],\n",
      "        [259,  51, 304,  25,  25, 318, 259,  25, 318, 259, 340, 279,  25, 340,\n",
      "         279, 279,  25,  25, 279, 134, 395, 246, 279, 228,  25, 304, 246, 318,\n",
      "         246, 137,  97, 199, 259, 395, 395, 134, 259, 259, 259, 134, 228, 279,\n",
      "          25, 395,  25, 199, 395, 246,  25, 304, 133, 133,  34, 133, 134, 318,\n",
      "         137, 304, 222, 134, 395, 395, 304,  25, 304, 246, 279, 395,  51,  34,\n",
      "          25,  25,  51, 137, 133, 124,  25,  89,  34,  34, 124, 134, 133,  25,\n",
      "         137, 246, 318, 246, 137, 395, 279,  34, 279,  25, 137, 246, 124, 304,\n",
      "         124, 137],\n",
      "        [259,  51, 304,  25,  25, 318, 259,  25, 318, 259, 340, 279,  25, 340,\n",
      "         279, 279,  34,  34, 279, 134, 395, 246, 279, 228,  25, 304, 246, 318,\n",
      "         246, 137,  97, 199, 259, 395, 395, 134, 259, 259, 259, 134, 228, 279,\n",
      "          25, 395,  25, 199, 395, 246,  25, 304, 133, 133,  34, 133, 134, 318,\n",
      "         137, 304, 222, 134, 395, 395, 304,  25, 304, 246, 279, 395,  51,  34,\n",
      "          25,  25,  51, 137, 133, 124,  34,  89,  34,  34, 124, 134, 133,  25,\n",
      "         137, 246, 318, 246, 137, 395, 279,  34, 279,  25, 137, 246, 124, 304,\n",
      "         124, 137],\n",
      "        [259,  51, 304,  25,  25, 318, 259,  25, 318, 259, 340, 279,  25, 340,\n",
      "         279, 279,  34,  34, 279, 134, 395, 246, 279, 228,  25, 304, 246, 318,\n",
      "         246, 137,  97, 199, 259, 395, 395, 134, 259, 259, 259, 134, 228, 279,\n",
      "          25, 395,  25, 199, 395, 246,  25, 304, 133, 133,  34, 133, 134, 318,\n",
      "         137, 304, 222, 134, 395, 395, 304,  25, 304, 246, 279, 395,  51,  34,\n",
      "          25,  25,  51, 137, 133, 124,  34,  89,  34,  34, 124, 134, 133,  25,\n",
      "         137, 246, 318, 246, 137, 395, 279,  34, 279,  25, 137, 246, 124, 304,\n",
      "         124, 137]], device='cuda:0')\n",
      "tensor([[ 25,  25,  25,  25,  25, 246, 246, 246, 246, 246,  25,  25,  25,  25,\n",
      "          25, 199, 199, 199, 199, 199, 222, 222, 222, 222, 222, 222, 222, 222,\n",
      "         222, 222, 134, 134, 134, 134, 134,  97,  97,  97,  97,  97, 137, 137,\n",
      "         137, 137, 137, 340, 340, 340, 340, 340, 124, 124, 124, 124, 124, 134,\n",
      "         134, 134, 134, 134, 259, 259, 259, 259, 259, 137, 137, 137, 137, 137,\n",
      "          89,  89,  89,  89,  89, 219, 219, 219, 219, 219, 340, 340, 340, 340,\n",
      "         340, 279, 279, 279, 279, 279, 134, 134, 134, 134, 134, 199, 199, 199,\n",
      "         199, 199],\n",
      "        [246, 246, 246, 246, 246, 219, 219, 219, 219, 219, 318, 318, 318, 318,\n",
      "         318, 279, 279, 279, 279, 279, 304, 304, 304, 304, 304, 219, 219, 219,\n",
      "         219, 219, 134, 134, 134, 134, 134, 304, 304, 304, 304, 304, 246, 246,\n",
      "         246, 246, 246, 340, 340, 340, 340, 340, 124, 124, 124, 124, 124, 134,\n",
      "         134, 134, 134, 134, 259, 259, 259, 259, 259,  97,  97,  97,  97,  97,\n",
      "         228, 228, 228, 228, 228, 219, 219, 219, 219, 219,  97,  97,  97,  97,\n",
      "          97,  89,  89,  89,  89,  89, 246, 246, 246, 246, 246, 199, 199, 199,\n",
      "         199, 199],\n",
      "        [228, 228, 228, 228, 228, 199, 199, 199, 199, 199, 137, 137, 137, 137,\n",
      "         137, 228, 228, 228, 228, 228, 222, 222, 222, 222, 222, 222, 222, 222,\n",
      "         222, 222, 318, 318, 318, 318, 318, 279, 279, 279, 279, 279, 318, 318,\n",
      "         318, 318, 318, 304, 304, 304, 304, 304, 304, 304, 304, 304, 304, 134,\n",
      "         134, 134, 134, 134,  97,  97,  97,  97,  97, 137, 137, 137, 137, 137,\n",
      "         199, 199, 199, 199, 199, 228, 228, 228, 228, 228, 228, 228, 228, 228,\n",
      "         228, 219, 219, 219, 219, 219, 134, 134, 134, 134, 134, 199, 199, 199,\n",
      "         199, 199],\n",
      "        [ 34,  34,  34,  34,  34, 219, 219, 219, 219, 219, 279, 279, 279, 279,\n",
      "         279, 199, 199, 199, 199, 199, 199, 199, 199, 199, 199,  34,  34,  34,\n",
      "          34,  34,  34,  34,  34,  34,  34, 340, 340, 340, 340, 340, 318, 318,\n",
      "         318, 318, 318, 124, 124, 124, 124, 124, 259, 259, 259, 259, 259, 199,\n",
      "         199, 199, 199, 199, 340, 340, 340, 340, 340, 246, 246, 246, 246, 246,\n",
      "         246, 246, 246, 246, 246, 395, 395, 395, 395, 395, 199, 199, 199, 199,\n",
      "         199, 279, 279, 279, 279, 279,  34,  34,  34,  34,  34, 304, 304, 304,\n",
      "         304, 304],\n",
      "        [246, 246, 246, 246, 246, 219, 219, 219, 219, 219, 219, 219, 219, 219,\n",
      "         219, 219, 219, 219, 219, 219, 304, 304, 304, 304, 304, 219, 219, 219,\n",
      "         219, 219, 222, 222, 222, 222, 222,  97,  97,  97,  97,  97,  89,  89,\n",
      "          89,  89,  89, 259, 259, 259, 259, 259,  25,  25,  25,  25,  25, 222,\n",
      "         222, 222, 222, 222, 340, 340, 340, 340, 340,  97,  97,  97,  97,  97,\n",
      "         318, 318, 318, 318, 318,  51,  51,  51,  51,  51,  97,  97,  97,  97,\n",
      "          97, 340, 340, 340, 340, 340,  34,  34,  34,  34,  34,  34,  34,  34,\n",
      "          34,  34],\n",
      "        [304, 304, 304, 304, 304, 279, 279, 279, 279, 279, 219, 219, 219, 219,\n",
      "         219, 340, 340, 340, 340, 340, 304, 304, 304, 304, 304,  34,  34,  34,\n",
      "          34,  34, 222, 222, 222, 222, 222, 279, 279, 279, 279, 279, 228, 228,\n",
      "         228, 228, 228, 340, 340, 340, 340, 340, 137, 137, 137, 137, 137, 222,\n",
      "         222, 222, 222, 222,  97,  97,  97,  97,  97, 133, 133, 133, 133, 133,\n",
      "          89,  89,  89,  89,  89, 219, 219, 219, 219, 219, 124, 124, 124, 124,\n",
      "         124,  89,  89,  89,  89,  89,  25,  25,  25,  25,  25, 222, 222, 222,\n",
      "         222, 222],\n",
      "        [ 25,  25,  25,  25,  25, 259, 259, 259, 259, 259, 124, 124, 124, 124,\n",
      "         124,  34,  34,  34,  34,  34, 222, 222, 222, 222, 222, 279, 279, 279,\n",
      "         279, 279, 133, 133, 133, 133, 133,  25,  25,  25,  25,  25,  34,  34,\n",
      "          34,  34,  34, 219, 219, 219, 219, 219, 259, 259, 259, 259, 259,  89,\n",
      "          89,  89,  89,  89, 340, 340, 340, 340, 340,  25,  25,  25,  25,  25,\n",
      "          89,  89,  89,  89,  89, 137, 137, 137, 137, 137,  89,  89,  89,  89,\n",
      "          89, 279, 279, 279, 279, 279, 137, 137, 137, 137, 137, 199, 199, 199,\n",
      "         199, 199],\n",
      "        [219, 219, 219, 219, 219, 124, 124, 124, 124, 124,  25,  25,  25,  25,\n",
      "          25, 279, 279, 279, 279, 279, 222, 222, 222, 222, 222, 246, 246, 246,\n",
      "         246, 246, 395, 395, 395, 395, 395, 134, 134, 134, 134, 134, 137, 137,\n",
      "         137, 137, 137, 259, 259, 259, 259, 259,  25,  25,  25,  25,  25, 199,\n",
      "         199, 199, 199, 199,  89,  89,  89,  89,  89,  89,  89,  89,  89,  89,\n",
      "          25,  25,  25,  25,  25, 219, 219, 219, 219, 219, 340, 340, 340, 340,\n",
      "         340, 133, 133, 133, 133, 133,  34,  34,  34,  34,  34,  34,  34,  34,\n",
      "          34,  34],\n",
      "        [ 25,  25,  25,  25,  25, 246, 246, 246, 246, 246,  25,  25,  25,  25,\n",
      "          25, 395, 395, 395, 395, 395, 304, 304, 304, 304, 304, 222, 222, 222,\n",
      "         222, 222, 318, 318, 318, 318, 318, 246, 246, 246, 246, 246, 199, 199,\n",
      "         199, 199, 199, 137, 137, 137, 137, 137, 340, 340, 340, 340, 340, 134,\n",
      "         134, 134, 134, 134, 259, 259, 259, 259, 259,  97,  97,  97,  97,  97,\n",
      "         124, 124, 124, 124, 124,  51,  51,  51,  51,  51, 340, 340, 340, 340,\n",
      "         340, 219, 219, 219, 219, 219,  25,  25,  25,  25,  25, 304, 304, 304,\n",
      "         304, 304],\n",
      "        [ 25,  25,  25,  25,  25,  25,  25,  25,  25,  25, 318, 318, 318, 318,\n",
      "         318, 134, 134, 134, 134, 134, 199, 199, 199, 199, 199, 219, 219, 219,\n",
      "         219, 219, 304, 304, 304, 304, 304,  25,  25,  25,  25,  25,  89,  89,\n",
      "          89,  89,  89, 304, 304, 304, 304, 304, 304, 304, 304, 304, 304,  89,\n",
      "          89,  89,  89,  89, 259, 259, 259, 259, 259,  51,  51,  51,  51,  51,\n",
      "         137, 137, 137, 137, 137,  89,  89,  89,  89,  89, 228, 228, 228, 228,\n",
      "         228, 219, 219, 219, 219, 219, 134, 134, 134, 134, 134,  34,  34,  34,\n",
      "          34,  34]], device='cuda:0')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:itm_py] *",
   "language": "python",
   "name": "conda-env-itm_py-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}